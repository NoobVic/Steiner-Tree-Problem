{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28fabbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = '../df/'\n",
    "ds_path = '../ds/'\n",
    "ds_suffix = '.stp'\n",
    "df_suffix = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e47fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "tmp = os.listdir(ds_path)\n",
    "ds_dict = {}\n",
    "for folder in tmp:\n",
    "    ds_dict.update({each[:8] : ds_path + folder + '/' + each for each in os.listdir(ds_path + folder + '/')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53c5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get files\n",
    "import os\n",
    "import pandas as pd\n",
    "df_files = os.listdir(df_path)\n",
    "df_files.remove(\"evaluation.csv\")\n",
    "df_eval = pd.read_csv(df_path+\"evaluation.csv\",index_col=0)\n",
    "df_samples = []\n",
    "for file in df_files:\n",
    "    df_samples.append(pd.read_csv(df_path+file,index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1946230",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = df_eval.sort_values(by=['ILP Runtime']).index[:-10]\n",
    "evalu_list = df_eval.sort_values(by=['ILP Runtime']).index[-10:]\n",
    "train_df = {filename : pd.read_csv(df_path+filename+df_suffix) for filename in train_list}\n",
    "evalu_df = {filename : pd.read_csv(df_path+filename+df_suffix) for filename in evalu_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4657b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def split_x_y(df_list):\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    x = df.drop(columns=['Node1','Node2','Weight','Label'])\n",
    "    y = df['Label']\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81d384e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fe18c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = split_x_y(list(train_df.values()) + list(evalu_df.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6642a1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &  Importance \\\\\n",
      "\\midrule\n",
      "LP                         &    0.461665 \\\\\n",
      "Normalized Weight          &    0.108099 \\\\\n",
      "Variance                   &    0.082869 \\\\\n",
      "Degree Centrality Max      &    0.052033 \\\\\n",
      "Eigenvector Centrality Max &    0.047566 \\\\\n",
      "Betweenness Centrality Max &    0.047523 \\\\\n",
      "Degree Centrality Min      &    0.045958 \\\\\n",
      "Local Rank j               &    0.041085 \\\\\n",
      "Eigenvector Centrality Min &    0.039031 \\\\\n",
      "Betweenness Centrality Min &    0.038027 \\\\\n",
      "Local Rank i               &    0.036145 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "# Default classifier is applied first\n",
    "clf_rf = RandomForestClassifier(class_weight='balanced')\n",
    "clf_rf.fit(X,Y)\n",
    "features = X.columns\n",
    "feature_importance = list(zip(features, clf_rf.feature_importances_))\n",
    "df = pd.DataFrame()\n",
    "for each in sorted(feature_importance,key=takeSecond, reverse=True):\n",
    "    df.loc[each[0],'Importance'] = each[1]\n",
    "print(df.to_latex(index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44c7111",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = split_x_y(list(train_df.values()))\n",
    "X_test, Y_test = split_x_y(list(evalu_df.values()))\n",
    "from sklearn import svm\n",
    "# Default classifier is applied first\n",
    "clf_svm = svm.SVC(class_weight='balanced', probability=True)\n",
    "clf_svm.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed166c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose threshold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "my_thresholds = [0.005,0.006,0.007,0.008,0.009]\n",
    "clf_thresholds = {}\n",
    "def evaluation_confusion(clf):\n",
    "    x_pruning = []\n",
    "    y_loss = []\n",
    "    clf_thresholds[clf.__class__.__name__] = []\n",
    "    for threshold in my_thresholds:\n",
    "        Y_pred_proba = clf.predict_proba(X_test)\n",
    "        Y_pred = (Y_pred_proba [:,1] >= threshold).astype('int')\n",
    "        tn, fp, fn, tp = confusion_matrix(Y_test,Y_pred).ravel()\n",
    "        matrix = confusion_matrix(Y_test,Y_pred)\n",
    "        x_pruning.append(round(100*(1-(tp+fp)/len(Y_pred)),2))\n",
    "        y_loss.append(round(100*(1-(tp)/(tp+fn)),2))\n",
    "        # If the threshold change cannot make change anymore on performance\n",
    "        if (y_loss[-1] != y_loss[0]) and (y_loss[-1] == y_loss[-2]):\n",
    "            y_loss = y_loss[:-1]\n",
    "            x_pruning = x_pruning[:-1]\n",
    "            print(\"The threshold <= {} are useless for classifier {}\".format(threshold, clf.__class__.__name__))\n",
    "            clf_thresholds[clf.__class__.__name__] = my_thresholds[:my_thresholds.index(threshold)]\n",
    "            break\n",
    "    # Every threshold number is useful\n",
    "    if len(clf_thresholds[clf.__class__.__name__]) == 0:\n",
    "        clf_thresholds[clf.__class__.__name__] = my_thresholds.copy()\n",
    "    print(\"Purning Rate(%):\", x_pruning)\n",
    "    print(\"Optimal Edges Loss Rate(%):\", y_loss)\n",
    "    \n",
    "evaluation_confusion(clf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ac258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def read_graph(name):\n",
    "    with open(name) as f:\n",
    "        lines = f.readlines()\n",
    "        arcs = []\n",
    "        for line in lines:\n",
    "            if line == '\\n': \n",
    "                continue\n",
    "            parts = line.split()\n",
    "            det = parts[0]\n",
    "            if det == 'Name':\n",
    "                name = parts[1]\n",
    "            elif det == 'Nodes':\n",
    "                n_vertices = int(parts[1])\n",
    "            elif det == 'Edges':\n",
    "                n_edges = int(parts[1])\n",
    "            elif det == 'E':\n",
    "                i = int(parts[1])\n",
    "                j = int(parts[2])\n",
    "                c = int(parts[3])\n",
    "                arcij = ((i,j),c)\n",
    "                arcji = ((j,i),c)\n",
    "                arcs.append(arcij)\n",
    "                arcs.append(arcji)\n",
    "            elif det == 'Terminals':\n",
    "                n_terminals = int(parts[1])\n",
    "        vertices = np.arange(1, int(n_vertices)+1)\n",
    "        vertices = vertices.tolist()\n",
    "        terminals = np.arange(1, int(n_terminals)+1)\n",
    "        terminals = terminals.tolist()\n",
    "        assert(int(n_edges) == len(arcs)/2)\n",
    "    f.close()\n",
    "    ### The format of graphs is D=(V,A,R)\n",
    "    return [vertices, arcs, terminals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024c2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "def formulation_3_ILP(graph, warm=None, cutoff=None, limit=None, P=None):\n",
    "    # set define\n",
    "    # N: All Nodes, E: Arcs, V: Terminals\n",
    "    # S: N - V Other nodes expect Terminals\n",
    "    N, E, V = graph\n",
    "    S = [each for each in N if (each not in V)]\n",
    "    \n",
    "    # Choose the first terminal as Root\n",
    "    root = V[0]\n",
    "    V = V[1:]\n",
    "    \n",
    "    # delete all the arcs that enter the source vertex\n",
    "    E = [arc for arc in E if not arc[0][1] == root]\n",
    "    \n",
    "    # create the tuple dictionary of arcs\n",
    "    E_dict = gp.tupledict(E)\n",
    "    \n",
    "    # model creation\n",
    "    m = gp.Model(\"Steiner_formulation_3\")\n",
    "    \n",
    "    E_dict_keys = E_dict.keys()\n",
    "    X_dict = []\n",
    "    for k in V:\n",
    "        for arc in E_dict_keys:\n",
    "            X_dict.append((arc[0], arc[1], k))\n",
    "            \n",
    "    # add variables\n",
    "    x = m.addVars(X_dict,lb=0,vtype=GRB.INTEGER, name='x') # size: |V| * |E|\n",
    "    y = m.addVars(E_dict_keys,vtype=GRB.INTEGER, name='y') # size: |E|\n",
    "    \n",
    "    # set objective value 2.1\n",
    "    m.setObjective(gp.quicksum(E_dict[i, j] * y[i, j] for (i, j) in E_dict_keys), GRB.MINIMIZE)\n",
    "                \n",
    "    # set cutoff\n",
    "    if cutoff != None:\n",
    "        m.Params.cutoff = cutoff\n",
    "    \n",
    "    # add constraints\n",
    "    for i in N:\n",
    "        for k in V:\n",
    "            # constraint 2.2\n",
    "            if i == root:\n",
    "                m.addConstr(x.sum(i,'*',k) - x.sum('*',i,k) == 1)\n",
    "            elif i == k:\n",
    "                m.addConstr(x.sum(i,'*',k) - x.sum('*',i,k) == -1)\n",
    "            else:\n",
    "                m.addConstr(x.sum(i,'*',k) - x.sum('*',i,k) == 0)\n",
    "    \n",
    "    # constraint 2.3\n",
    "    for i,j,k in X_dict:\n",
    "        m.addConstr(x[i,j,k] <= y[i,j])\n",
    "    \n",
    "    # Warm start\n",
    "    if warm != None:\n",
    "        for i,j in warm:\n",
    "            i,j = int(i), int(j)\n",
    "            y[i,j].Start = 1.0\n",
    "\n",
    "    # Hard prune SHOULD NOT assign soft to 0\n",
    "    # Instead, it should replace E with Pruned set\n",
    "    if (limit != None) & (P != None):\n",
    "        P = [arc for arc in P if not arc[0][1] == root]\n",
    "        y_P = [y[i,j] for ((i,j),c) in P]\n",
    "        m.addConstr(gp.quicksum(y) - gp.quicksum(y_P) <= limit)\n",
    "    \n",
    "    # update the model\n",
    "    m.update()\n",
    "    \n",
    "    # optimize the model\n",
    "    m.optimize()\n",
    "    \n",
    "    # save the optimal solution\n",
    "    opt_cost = m.objVal\n",
    "    \n",
    "    opt_edges = []\n",
    "    opt_vertices = []\n",
    "    \n",
    "    for v in m.getVars():\n",
    "        # save the vertices\n",
    "        if v.varName.startswith('y') and v.x != 0:\n",
    "            opt_vertices.append((v.varName[2:-1], v.x))\n",
    "                \n",
    "    opt_runtime = m.Runtime\n",
    "    \n",
    "    return opt_vertices, opt_cost, opt_runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad88157",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "part_b_list = {}\n",
    "for name in evalu_df.keys():\n",
    "    sample = evalu_df[name]\n",
    "    graph = sample[['Node1','Node2','Weight','LP','Label']]\n",
    "    x = sample.drop(columns=['Node1','Node2','Weight','Label'])\n",
    "    y_proba = clf_svm.predict_proba(x)\n",
    "    y = (y_proba[:,1] >= 0.006).astype('int')\n",
    "    graph.insert(len(graph.columns),'Predict', y)\n",
    "    graph = graph.loc[(graph['LP'] > 0) | (graph['Predict']) > 0]\n",
    "    arcs = []\n",
    "    for index, row in graph.iterrows():\n",
    "        i = int(row['Node1'])\n",
    "        j = int(row['Node2'])\n",
    "        c = int(row['Weight'])\n",
    "        arcij = ((i,j),c)\n",
    "        arcji = ((j,i),c)\n",
    "        arcs.append(arcij)\n",
    "        arcs.append(arcji)\n",
    "    # Graph is the un-pruned graph\n",
    "    graph = read_graph(ds_dict[name])\n",
    "\n",
    "    # PART A: Calculate ILP by Pruned Set\n",
    "    # graph: 0: Nodes, 1: Arcs, :2 Terminals\n",
    "    sol, obj, rt = formulation_3_ILP([graph[0], arcs, graph[2]])\n",
    "    df_eval.loc[name,'ILP Objective Pruned'] = obj\n",
    "    df_eval.loc[name,'ILP Runtime Pruned'] = rt\n",
    "    if float(obj) != float(df_eval.loc[name,'ILP Objective']):\n",
    "        part_b_list[name] = [sol, obj, arcs]\n",
    "df_eval.to_csv(df_path+\"evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fd0fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_c_list = {}\n",
    "for name in part_b_list.keys():\n",
    "    # Graph is the un-pruned graph\n",
    "    graph = read_graph(ds_dict[name])\n",
    "    sol, obj, arcs = part_b_list[name]\n",
    "    \n",
    "    # PART B:\n",
    "    # When I didn't get the optimal solution\n",
    "    # Warm start is applied and loop with N soft pruning\n",
    "    for N in [1,2]:\n",
    "        sol = [each[0].split(',') for each in sol]\n",
    "        sol, obj, rt = formulation_3_ILP(graph, sol, obj, N, arcs)\n",
    "        df_eval.loc[name,'ILP Objective N = {}'.format(N)] = obj\n",
    "        df_eval.loc[name,'ILP Runtime N = {}'.format(N)] = rt\n",
    "        df_eval.to_csv(df_path+\"evaluation.csv\")\n",
    "        if float(obj) == float(df_eval.loc[name,'ILP Objective']):\n",
    "            break\n",
    "            \n",
    "    if float(obj) != float(df_eval.loc[name,'ILP Objective']):\n",
    "        sol, obj, rt = formulation_3_ILP([graph[0], arcs, graph[2]])\n",
    "        part_c_list[name] = [sol, obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90c0fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in part_c_list.keys():\n",
    "    graph = read_graph(ds_dict[name])\n",
    "    sol, obj = part_c_list[name]\n",
    "    \n",
    "    # PART C\n",
    "    # if the optimal result is still not gained, use warm only          \n",
    "    if float(obj) != float(df_eval.loc[name,'ILP Objective']):\n",
    "        sol, obj, rt = formulation_3_ILP([graph[0], arcs, graph[2]])\n",
    "        sol = [each[0].split(',') for each in sol]\n",
    "        sol, obj, rt = formulation_3_ILP(graph, sol, obj)\n",
    "        df_eval.loc[name,'ILP Objective Warm'] = obj\n",
    "        df_eval.loc[name,'ILP Runtime Warm'] = rt\n",
    "        df_eval.to_csv(df_path+\"evaluation.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ead6f",
   "metadata": {},
   "source": [
    "James Fitzpatrick, Deepak Ajwani, Paula Carroll:\n",
    "Learning to Sparsify Travelling Salesman Problem Instances. CPAIOR 2021: 410-426\n",
    "\n",
    "Dena Tayebi, Saurabh Ray and Deepak Ajwani: \n",
    "Learning to Sparsify instance of k-median and related problems. ALENEX 2022\n",
    "\n",
    "A dual ascent approach for steiner tree problems on a directed graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7a676abbc58fb72a4139e964996bdbf10c701e0b1ca7f6ed9a8294b6eab108e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
