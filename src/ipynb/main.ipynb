{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from script.formulation import *\n",
    "from script.functions import *\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for paths\n",
    "filenames = get_selected_files()\n",
    "ds_paths = dict(zip(filenames, get_paths(filenames, 'ds')))\n",
    "df_paths = dict(zip(filenames, get_paths(filenames, 'df')))\n",
    "log_paths = dict(zip(filenames, get_paths(filenames, 'log')))\n",
    "test_samples = ['i160-314',\n",
    "                'i160-245',\n",
    "                'i160-313',\n",
    "                'i160-242',\n",
    "                'i160-241',\n",
    "                'i160-244',\n",
    "                'i160-343',\n",
    "                'i160-344',\n",
    "                'i160-341',\n",
    "                'i160-345',\n",
    "                'i160-342']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataframes\n",
    "train_list = []\n",
    "test_list = []\n",
    "for file in filenames:\n",
    "    tmp_df, runtime = dataframe_generate(ds_paths[file], log_paths[file])\n",
    "    if file in test_samples:\n",
    "        test_list.append(tmp_df)\n",
    "    else:\n",
    "        train_list.append(tmp_df)\n",
    "df_train = pd.concat(train_list)\n",
    "df_test = pd.concat(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the train, test set for Evaluation 1\n",
    "x_train, y_train = split_x_y(df_train)\n",
    "x_test, y_test = split_x_y(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    \"Support Vector Machine\" : SVC(\n",
    "        class_weight='balanced', probability=True, random_state=0),\n",
    "    \"Random Forest\" : RandomForestClassifier(class_weight='balanced'),\n",
    "    \"Logistic Regression\" : LogisticRegression(\n",
    "        class_weight='balanced', max_iter=1000, random_state=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for clf in clfs:\n",
    "#     clfs[clf].fit(x_train, y_train)\n",
    "# plt.hist(clfs[\"Support Vector Machine\"].predict_proba(x_test)[:,1], bins=20)\n",
    "# plt.hist(clfs[\"Random Forest\"].predict_proba(x_test)[:,1], bins=20)\n",
    "# plt.hist(clfs[\"Logistic Regression\"].predict_proba(x_test)[:,1], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust thresholds for LR classifier\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Training...\")\n",
    "clfs['Logistic Regression'].fit(x_train, y_train)\n",
    "print(\"Train Finished\")\n",
    "print(\"Feature Importance:\")\n",
    "print(x_train.std()*clfs['Logistic Regression'].coef_[0])\n",
    "print(\"Adjust Thresholds:\")\n",
    "thresholds = np.arange(0,1,0.02)\n",
    "for threshold in thresholds:\n",
    "    y_pred_proba = clfs['Logistic Regression'].predict_proba(x_test)\n",
    "    y_pred = (y_pred_proba[:,1] >= threshold).astype('int')\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test,y_pred).ravel()\n",
    "    print(\"Threshold:\",np.round(threshold,2), \n",
    "        \"FN rate:\", np.round(fn/(fn+tp), 2),\n",
    "        \"Pruning Rate:\", np.round(100*(fn+tn)/len(y_pred),2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation on each samples in test_list (Evaluation 2)\n",
    "thresholds = np.arrange(0.05, 0.5, 0.05)\n",
    "clf = clfs['Logistic Regression']\n",
    "for filename in test_samples:\n",
    "    ds_path = ds_paths[filename]\n",
    "    log_path = log_paths[filename]\n",
    "    for threshold in thresholds:\n",
    "        solve(filename, clf, ds_path, log_path, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "253cd15c32ffb283b0558be93b097dc27093fe6b891853f454fa08d2f15e4a97"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
